{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * @file staticInputs.ipynb\n",
    "#  * @author Samay Pashine (samay@iiti.ac.in)\n",
    "#  * @modified Samay Pashine (samay@iiti.ac.in)\n",
    "#  * @brief Open all dataset file, preprocess, & save the static input in feather file incrementally.\n",
    "#  * @version 3.0\n",
    "#  * @date 2021-11-12\n",
    "#  * @copyright Copyright (c) 2021\n",
    "#  */\n",
    "\n",
    "# Importing necessary libraries.\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import time\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from constants import *\n",
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipData(shape_file_path, plantData, matyData, yieldData):\n",
    "    \"\"\" Clip the .nc4 data using shape file passed.\n",
    "\n",
    "    Args:\n",
    "        shape_file_path (str): Path to shape file for clipping the data.\n",
    "        plantData (xarray.Dataset): nc4 Data of plant-file\n",
    "        matyData (xarray.Dataset): nc4 Data of maturity-file\n",
    "        yieldData (xarray.Dataset): nc4 Data of yield\n",
    "\n",
    "    Returns:\n",
    "        [xarray.Dataset]: Clipped nc4 data.\n",
    "    \"\"\"\n",
    "    # Reading the shape file using geopandas.\n",
    "    geodf = geopandas.read_file(shape_file_path)\n",
    "    \n",
    "    # Configuring the rio engine for clipping.\n",
    "    plantData = plantData.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    matyData = matyData.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    yieldData = yieldData.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "    # Clipping the data.\n",
    "    plantData = plantData.rio.clip(geodf.geometry.apply(mapping), geodf.crs, from_disk=True)\n",
    "    matyData = matyData.rio.clip(geodf.geometry.apply(mapping), geodf.crs, from_disk=True)\n",
    "    yieldData = yieldData.rio.clip(geodf.geometry.apply(mapping), geodf.crs, from_disk=True)\n",
    "\n",
    "    # Renaming the cooridnates of the data.\n",
    "    yieldData = yieldData.rename(x='lon', y='lat')\n",
    "    yieldData = yieldData.rio.set_spatial_dims(x_dim='lon', y_dim='lat', inplace=True)\n",
    "\n",
    "    return plantData, matyData, yieldData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDatasets(yield_filePath, plant_filePath, maty_filePath, crop_name):\n",
    "    \"\"\"Load datasets, and unify them in a data frame with all essential features.\n",
    "\n",
    "    Args:\n",
    "        yield_filePath ([str]): Complete yield file path.\n",
    "        plant_filePath ([str]): Complete plant-day file path.\n",
    "        maty_filePath ([str]): Complete maty-day file path.\n",
    "        crop_name ([str]): Name of crop.\n",
    "\n",
    "    Returns:\n",
    "        yieldDF([pd.DataFrame]): Pandas DataFrame with all features combined.\n",
    "    \"\"\"\n",
    "    # Loading datasets files without decoding time variable.\n",
    "    plantData = xr.open_dataset(plant_filePath, engine='rasterio', decode_times=False)\n",
    "    matyData = xr.open_dataset(maty_filePath, engine='rasterio', decode_times=False)\n",
    "    yieldData = xr.open_dataset(yield_filePath, engine='rasterio', decode_times=False)\n",
    "\n",
    "    # Clipping the data.\n",
    "    plantData, matyData, yieldData = clipData(os.path.join(shape_file_path, \"4_states/4_states.shp\"), plantData, matyData, yieldData)\n",
    "\n",
    "    # Decoding time variable of the dataset using pandas.\n",
    "    initialYear = 1979\n",
    "    timeArray = initialYear + yieldData.variables['time'].values\n",
    "\n",
    "    plantData['time'] = timeArray.astype(int)\n",
    "    matyData['time'] = timeArray.astype(int)\n",
    "    yieldData['time'] = timeArray.astype(int)\n",
    "\n",
    "    # Converting dataset in DataFrame format for modification.\n",
    "    plantDF = plantData['plant-day_{}'.format(crop_name)].to_dataframe()\n",
    "    matyDF = matyData['maty-day_{}'.format(crop_name)].to_dataframe()\n",
    "    yieldDF = yieldData['yield_{}'.format(crop_name)].to_dataframe()\n",
    "\n",
    "    # Adding columns from plantDF and matyDF in yieldDF.\n",
    "    yieldDF['plant-day'] = plantDF['plant-day_{}'.format(crop_name)]\n",
    "    yieldDF['maturity-day'] = yieldDF['plant-day'] + matyDF['maty-day_{}'.format(crop_name)]\n",
    "    yieldDF = yieldDF.rename(columns={'x': 'lon', 'y': 'lat'})\n",
    "\n",
    "    # Deleting unnecessary variables to conserve space in the system.\n",
    "    del plantDF, matyDF, plantData, matyData, yieldData\n",
    "    return yieldDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surfaceFeatureExtractor(yieldDF, yield_filePath):\n",
    "    \"\"\"Extract surface featueres from individual netCDF file and combine it with yield DataFrame.\n",
    "\n",
    "    Args:\n",
    "        yieldDF (pandas.DataFrame): DataFrame with plant-day, maty-day and yield features.\n",
    "        yield_filePath (str): Path of yield netCDF file.\n",
    "\n",
    "    Returns:\n",
    "        yieldDF (pandas.DataFrame): Return Dataframe with additional CWTN-A features.\n",
    "    \"\"\"\n",
    "    # Splitting filename to get individual un-processed feature.\n",
    "    splittedFilename = yield_filePath.split('/')[-1].split('_')\n",
    "    raw_CO2, raw_W = splittedFilename[9], splittedFilename[11]\n",
    "    raw_T, raw_N = splittedFilename[10], splittedFilename[12]\n",
    "    raw_A = splittedFilename[13]\n",
    "\n",
    "    # Processing individual feature.\n",
    "    CO2, N, A = int(raw_CO2[1:]), int(raw_N[1:]), int(raw_A[1])\n",
    "    T, W = raw_T.split('-'), raw_W.split('-')\n",
    "\n",
    "    if len(T) > 1:\n",
    "        T = int(T[-1])\n",
    "    else:\n",
    "        T = int(T[0][1:])\n",
    "\n",
    "    if len(W) > 1:\n",
    "        W = int(W[-1])\n",
    "    else:\n",
    "        W = W[0].strip()\n",
    "        if len(W) > 3:\n",
    "            W = np.inf\n",
    "        else:\n",
    "            W = int(W[1:])\n",
    "\n",
    "    # print(\"[INFO]. CO2 : \", CO2)\n",
    "    # print(\"[INFO].  W  : \", W)\n",
    "    # print(\"[INFO].  T : \", T)\n",
    "    # print(\"[INFO].  N : \", N)\n",
    "    # print(\"[INFO].  A : \", A)\n",
    "\n",
    "    # Adding surface features in yield DataFrame.\n",
    "    yieldDF['CO2'] = CO2\n",
    "    yieldDF['W'] = W\n",
    "    yieldDF['T'] = T\n",
    "    yieldDF['N'] = N\n",
    "    yieldDF['A'] = A\n",
    "\n",
    "    # Clearing the memory buffer and deleting the un-necessary variables.\n",
    "    gc.collect()\n",
    "    del raw_CO2, raw_A, raw_N, raw_T, raw_W, splittedFilename, CO2, W, T, N, A\n",
    "    \n",
    "    return yieldDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soilFeatureCombine(yieldDF, soil_file_path):\n",
    "    \"\"\"Access the HWSD soil v2.2 netcdf file and add soil features to the yield DataFrame.\n",
    "\n",
    "    Args:\n",
    "        yieldDF (pandas.DataFrame): yield Dataframe with surface features.\n",
    "        soil_file_path (str): HWSD soil netCDF path.\n",
    "\n",
    "    Returns:\n",
    "        yieldDF (pandas.DataFrame): DataFrame with soil features.\n",
    "    \"\"\"\n",
    "    # Reading HWSD file and converting it to dataframe.\n",
    "    soilData = xr.open_dataset(soil_file_path)\n",
    "    soilDF = soilData.to_dataframe().reset_index()\n",
    "\n",
    "    # Dropping additional features from the file to conserve computation power.\n",
    "    soilDF = soilDF.drop(columns=['mu_global', 'bulk_density', 'root_obstacles', 'impermeable_layer', 'ece', 'bs_soil', 'issoil'])\n",
    "\n",
    "    # Dropping any row with null value.\n",
    "    soilDF = soilDF.dropna(how='any')\n",
    "\n",
    "    # Merging yield DF and soil DF on latitude and longitude basis.\n",
    "    yieldDF = pd.merge(yieldDF, soilDF, on=['lat', 'lon'], how='inner')\n",
    "    return yieldDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1512/1512 [1:34:01<00:00,  3.73s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Driver Code which saves the finalized static inputs dataset in .feather format.\n",
    "    \"\"\"\n",
    "    # Initializing variables.\n",
    "    # plant_dir = \"./ggcmi/phase2_outputs/dataset/plant-day/\"\n",
    "    # maty_dir = \"./ggcmi/phase2_outputs/dataset/maty-day/\"\n",
    "    # yield_dir = \"./ggcmi/phase2_outputs/dataset/yield/\"\n",
    "    # soil_file_path = \"./ggcmi/HWSD/HWSD_soil_data_on_cropland_v2.2.nc\"\n",
    "\n",
    "    count, total_files = 1, len(glob.glob(yield_dir + \"*.nc4\"))\n",
    "    prevFile, DF = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Loop to go through each file in plant-day, maty-day and yield folder.\n",
    "    for filename in tqdm(glob.glob(yield_dir + \"*.nc4\")):\n",
    "        \n",
    "        yield_filePath = filename\n",
    "        filenameList = yield_filePath.split('/')[-1].split('_')\n",
    "\n",
    "        crop_name = filenameList[4]\n",
    "\n",
    "        filenameList[3] = 'plant-day'\n",
    "        plant_filePath = plant_dir + '_'.join(filenameList)\n",
    "\n",
    "        filenameList[3] = 'maty-day'\n",
    "        maty_filePath = maty_dir + '_'.join(filenameList)\n",
    "\n",
    "        # Condition to check if the corresponding files of plant-day and maty-day exists.\n",
    "        if not os.path.exists(plant_filePath) or not os.path.exists(maty_filePath):\n",
    "            print(\"[ERROR]. File does not exists.\")\n",
    "            print(\"[ERROR]. Passing through this iteration without change.\")\n",
    "            count += 1\n",
    "            time.sleep(3)\n",
    "            pass\n",
    "        \n",
    "        # print(\"[INFO]. plant-day file Path  : \", plant_filePath)\n",
    "        # print(\"[INFO]. maty-day file Path   : \", maty_filePath)\n",
    "        # print(\"[INFO]. yield file Path      : \", yield_filePath)\n",
    "        \n",
    "        # print(\"\\n\\n\\n\\n[PHASE 1]. Starting Loading Datasets.\")\n",
    "        yieldDF = loadDatasets(yield_filePath, plant_filePath, maty_filePath, crop_name)\n",
    "        # print(\"[PHASE 1]. Datasets Loaded Successfully.\")\n",
    "\n",
    "        # print(\"\\n[PHASE 2]. Starting Surface Feature Extraction.\")\n",
    "        yieldDF = surfaceFeatureExtractor(yieldDF, yield_filePath)\n",
    "        # print(\"[PHASE 2]. Surface Feature Extracted Successfully.\")\n",
    "\n",
    "        yieldDF = yieldDF.reset_index()\n",
    "        yieldDF = yieldDF.dropna(how='any')\n",
    "\n",
    "        # print(\"\\n[PHASE 3]. Starting Soil Feature Extraction.\")\n",
    "        yieldDF = soilFeatureCombine(yieldDF, soil_file_path)\n",
    "        # print(\"[PHASE 3]. Soil Feature Extracted Successfully.\")\n",
    "\n",
    "        # Changing the column format of the dataframe.\n",
    "        # yieldDF.gravel = yieldDF.gravel.astype(int)\n",
    "        # yieldDF.clay = yieldDF.clay.astype(int)\n",
    "        # yieldDF.silt = yieldDF.silt.astype(int)\n",
    "        # yieldDF.sand = yieldDF.sand.astype(int)\n",
    "        # yieldDF.awc = yieldDF.awc.astype(int)\n",
    "        # yieldDF.cec_soil = yieldDF.cec_soil.astype(int)\n",
    "        # yieldDF.texture_class = yieldDF.texture_class.astype(int)\n",
    "        # yieldDF.CO2 = yieldDF.CO2.astype(int)\n",
    "        # yieldDF['plant-day'] = yieldDF['plant-day'].astype(int)\n",
    "        # yieldDF['maturity-day'] = yieldDF['maturity-day'].astype(int)\n",
    "\n",
    "        # Shuffling the dataframe.\n",
    "        yieldDF = yieldDF.sample(frac = 1)\n",
    "        \n",
    "        # Concatenating the finalized DF from each file.\n",
    "        prevFile = pd.concat([prevFile, yieldDF], ignore_index=True)\n",
    "\n",
    "        yieldDF[\"yield_{}\".format(crop_name)] = np.round(yieldDF[\"yield_{}\".format(crop_name)])\n",
    "        count += 1\n",
    "        \n",
    "        # Saving the DF in feather format after every specified iteration or when finished.\n",
    "        if count % 10 == 0 or count == total_files:\n",
    "            if os.path.isfile(os.path.join(input_dir, 'static.feather')):\n",
    "                DF = pd.read_feather(os.path.join(input_dir, 'static.feather'))\n",
    "                DF = DF.sample(frac = 1)\n",
    "                DF = pd.concat([DF, prevFile], ignore_index=True)\n",
    "                os.system(\"rm -rf {}\".format(os.path.join(input_dir, 'static.feather')))\n",
    "            else:\n",
    "                DF = DF.reset_index()\n",
    "            \n",
    "            DF = DF.reset_index(drop=True)\n",
    "            DF.to_feather(os.path.join(input_dir, 'static.feather'), compression='lz4')\n",
    "\n",
    "            # Clearing the memory buffer, deleting un-necessary variables and resetting prevFile and DF.\n",
    "            del prevFile, DF\n",
    "            prevFile, DF = pd.DataFrame(), pd.DataFrame()\n",
    "            gc.collect()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
