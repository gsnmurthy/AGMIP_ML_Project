{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * @file inputFinalizer.ipynb\n",
    "#  * @author Samay Pashine (samay@iiti.ac.in)\n",
    "#  * @modified Samay Pashine (samay@iiti.ac.in)\n",
    "#  * @brief Read static input file in chunks, merge it with dynamic input file on ['time', 'lat', 'lon'] basis and save them.\n",
    "#  * @version 3.0\n",
    "#  * @date 2021-11-12\n",
    "#  * @copyright Copyright (c) 2021\n",
    "#  */\n",
    "\n",
    "# Importing necessary libraries.\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "from constants import *\n",
    "import pyarrow.ipc as ipc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_feather_in_chunks(filepath):\n",
    "    \"\"\"Function to read feather file in chunks instead of all at once.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path of final_input feather file.\n",
    "\n",
    "    Yields:\n",
    "        data_df [pandas.DataFrame]: return pandas Dataframe from the feather file.\n",
    "    \"\"\"\n",
    "    with ipc.RecordBatchFileReader(filepath) as reader:\n",
    "        for batch_index in range(reader.num_record_batches):\n",
    "            if batch_index == 0:\n",
    "                batch = reader.get_batch(batch_index).to_pandas(use_threads=True, timestamp_as_object=True, )\n",
    "            else:\n",
    "                new_batch = reader.get_batch(batch_index).to_pandas(use_threads=True, timestamp_as_object=True, )\n",
    "                data_df = pd.concat([batch, new_batch], ignore_index=True)\n",
    "                batch = data_df\n",
    "            \n",
    "            # Instead of taking just one batch with 65,000 rows (approx.), \n",
    "            # we let the loop iterate over batches until it triggers the condition below.\n",
    "            if (batch_index + 1) % 2 == 0:\n",
    "                batch = pd.DataFrame()\n",
    "                yield data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Driver code which starts the whole process and saves the final input files in the corresponding directory. \"\"\"\n",
    "    file_count = 1\n",
    "    \n",
    "    # Reading dynamic input file.\n",
    "    dynamic = pd.read_feather(os.path.join(input_dir, \"dynamic.feather\"))\n",
    "    \n",
    "    for batch in read_feather_in_chunks(os.path.join(input_dir, \"static.feather\")):\n",
    "        # Formatting the time column in batch for merger.\n",
    "        batch.time = batch.time.astype(int)\n",
    "\n",
    "        # Mergine the dataframes on the ['time', 'lat', 'lon'] basis.\n",
    "        final = pd.merge(batch, dynamic, on=['time', 'lat', 'lon'], how='inner')\n",
    "        \n",
    "        # Shuffling the dataframe before saving them.\n",
    "        final = final.sample(frac = 1)\n",
    "\n",
    "        # Loop to calculate the tasmax, tasmin and precipitation_flux in the batch.\n",
    "        # print(\"[INFO]. Calculating the Perturbations and additional inputs.\")\n",
    "        # for i in tqdm(range(len(final))):\n",
    "        #     final.iloc[i, 24] += final.iloc[i, 10]\n",
    "        #     final.iloc[i, 25] += final.iloc[i, 10]    \n",
    "        #     if final.iloc[i, 9] != np.inf:\n",
    "        #         final.iloc[i, 26] = (1 + final.iloc[i, 9] / 100) * final.iloc[i, 26]\n",
    "        # final = final.drop(columns=['index_x', 'index_y', 'spatial_ref', 'W', 'T'])\n",
    "        \n",
    "        final = final.reset_index()\n",
    "        final.to_feather(os.path.join(input_dir, final_inputs_dir, \"input_file_{}.feather\".format(file_count)), compression='lz4')\n",
    "        \n",
    "        # Clearing the memory buffer.\n",
    "        gc.collect()\n",
    "        \n",
    "        print(\"[INFO]. Batch {} has been processed and saved.\".format(file_count))\n",
    "        file_count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
