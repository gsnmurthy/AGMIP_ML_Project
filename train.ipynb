{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * @file train.ipynb\n",
    "#  * @author Samay Pashine (samay@iiti.ac.in)\n",
    "#  * @modified Samay Pashine (samay@iiti.ac.in)\n",
    "#  * @brief Train the neural network model to predict yield on crop outputs, soil and climate basis.\n",
    "#  * @version 2.0\n",
    "#  * @date 2021-11-12\n",
    "#  * @copyright Copyright (c) 2021\n",
    "#  */\n",
    "\n",
    "# Importing necessary libraries.\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.ipc as ipc\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import config\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, optimizers\n",
    "from tensorflow.keras.layers import Dense, Concatenate\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_growth_GPU():\n",
    "    \"\"\" Enabling memory growth in GPU (if present) for training the model. \"\"\"\n",
    "    try:\n",
    "        physicalDevices = config.experimental.list_physical_devices('GPU')\n",
    "        config.experimental.set_memory_growth(physicalDevices[0], True)\n",
    "    except:\n",
    "        print(\"[ERR]. Could not enable the memory growth in GPU. Switching to CPU for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_feather_in_chunks(filepath):\n",
    "    \"\"\"Function to read feather file in chunks instead of all at once.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path of final_input feather file.\n",
    "\n",
    "    Yields:\n",
    "        data_df [pandas.DataFrame]: return pandas Dataframe from the feather file.\n",
    "    \"\"\"\n",
    "    with ipc.RecordBatchFileReader(filepath) as reader:\n",
    "        for batch_index in range(reader.num_record_batches):\n",
    "            if batch_index == 0:\n",
    "                batch = reader.get_batch(batch_index).to_pandas(use_threads=True, timestamp_as_object=True, )\n",
    "            else:\n",
    "                new_batch = reader.get_batch(batch_index).to_pandas(use_threads=True, timestamp_as_object=True, )\n",
    "                data_df = pd.concat([batch, new_batch], ignore_index=True)\n",
    "                batch = data_df\n",
    "            \n",
    "            # Instead of taking just one batch with 65,000 rows (approx.), \n",
    "            # we let the loop iterate over batches until it triggers the condition below.\n",
    "            if (batch_index + 1) % 12 == 0:\n",
    "                batch = pd.DataFrame()\n",
    "                yield data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 00:37:27.271300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-13 00:37:27.281331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-13 00:37:27.281835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]. Pre-Processing Batch-1 Inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 786432/786432 [1:13:28<00:00, 178.39it/s]\n",
      "2021-11-13 01:51:02.234080: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-13 01:51:02.240578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-13 01:51:02.241352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-13 01:51:02.241976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-13 01:51:06.594681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-13 01:51:06.595683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-13 01:51:06.596450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-13 01:51:06.604375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3219 MB memory:  -> device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\n",
      "2021-11-13 01:51:07.791699: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2021-11-13 01:51:07.791744: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2021-11-13 01:51:07.832026: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2021-11-13 01:51:07.832661: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2021-11-13 01:51:07.832918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2021-11-13 01:51:07.833029: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: error 999: \n",
      "2021-11-13 01:51:07.833066: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2021-11-13 01:51:07.833078: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2021-11-13 01:51:07.833089: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1682] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2021-11-13 01:51:07.833134: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2021-11-13 01:51:07.833171: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2021-11-13 01:51:07.833183: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2021-11-13 01:51:07.833193: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1773] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 01:51:19.939920: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8300\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda-11.2/lib64/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 505/3933 [==>...........................] - ETA: 1:39 - loss: 0.4200 - rmse: 0.6480 - mae: 0.5486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 01:51:36.422577: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2021-11-13 01:51:36.422625: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2021-11-13 01:51:36.422710: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2021-11-13 01:51:36.422728: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2021-11-13 01:51:36.422738: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2021-11-13 01:51:36.422747: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1682] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 519/3933 [==>...........................] - ETA: 1:39 - loss: 0.4201 - rmse: 0.6482 - mae: 0.5488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 01:51:37.067614: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2021-11-13 01:51:37.067900: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2021-11-13 01:51:37.067929: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2021-11-13 01:51:37.067939: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1773] function cupti_interface_->Finalize()failed with error \n",
      "2021-11-13 01:51:37.195767: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2021-11-13 01:51:37.195806: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2021-11-13 01:51:37.195814: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:526]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-11-13 01:51:37.211248: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 520/3933 [==>...........................] - ETA: 1:41 - loss: 0.4201 - rmse: 0.6481 - mae: 0.5487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 01:51:37.270257: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37\n",
      "\n",
      "2021-11-13 01:51:37.280271: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37/samay.trace.json.gz\n",
      "2021-11-13 01:51:37.393705: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37\n",
      "\n",
      "2021-11-13 01:51:37.403326: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37/samay.memory_profile.json.gz\n",
      "2021-11-13 01:51:37.404955: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37\n",
      "Dumped tool data for xplane.pb to ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37/samay.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37/samay.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37/samay.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37/samay.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/20211113-015107/plugins/profile/2021_11_13_01_51_37/samay.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3933/3933 [==============================] - 141s 32ms/step - loss: 0.4145 - rmse: 0.6438 - mae: 0.5446 - val_loss: 0.4119 - val_rmse: 0.6418 - val_mae: 0.5430\n",
      "Epoch 2/100\n",
      "3933/3933 [==============================] - 125s 32ms/step - loss: 0.4077 - rmse: 0.6385 - mae: 0.5401 - val_loss: 0.4052 - val_rmse: 0.6366 - val_mae: 0.5386\n",
      "Epoch 3/100\n",
      "3933/3933 [==============================] - 125s 32ms/step - loss: 0.4012 - rmse: 0.6334 - mae: 0.5357 - val_loss: 0.3988 - val_rmse: 0.6315 - val_mae: 0.5342\n",
      "Epoch 4/100\n",
      "3933/3933 [==============================] - 126s 32ms/step - loss: 0.3949 - rmse: 0.6284 - mae: 0.5313 - val_loss: 0.3926 - val_rmse: 0.6266 - val_mae: 0.5298\n",
      "Epoch 5/100\n",
      "3933/3933 [==============================] - 126s 32ms/step - loss: 0.3889 - rmse: 0.6236 - mae: 0.5270 - val_loss: 0.3867 - val_rmse: 0.6219 - val_mae: 0.5255\n",
      "Epoch 6/100\n",
      "3933/3933 [==============================] - 126s 32ms/step - loss: 0.3831 - rmse: 0.6189 - mae: 0.5228 - val_loss: 0.3810 - val_rmse: 0.6172 - val_mae: 0.5213\n",
      "Epoch 7/100\n",
      "3933/3933 [==============================] - 126s 32ms/step - loss: 0.3774 - rmse: 0.6144 - mae: 0.5186 - val_loss: 0.3754 - val_rmse: 0.6127 - val_mae: 0.5171\n",
      "Epoch 8/100\n",
      "3933/3933 [==============================] - 126s 32ms/step - loss: 0.3720 - rmse: 0.6099 - mae: 0.5144 - val_loss: 0.3701 - val_rmse: 0.6083 - val_mae: 0.5129\n",
      "Epoch 9/100\n",
      "3933/3933 [==============================] - 127s 32ms/step - loss: 0.3668 - rmse: 0.6057 - mae: 0.5104 - val_loss: 0.3650 - val_rmse: 0.6041 - val_mae: 0.5090\n",
      "Epoch 10/100\n",
      "3933/3933 [==============================] - 127s 32ms/step - loss: 0.3619 - rmse: 0.6016 - mae: 0.5065 - val_loss: 0.3601 - val_rmse: 0.6001 - val_mae: 0.5051\n",
      "Epoch 11/100\n",
      "3933/3933 [==============================] - 127s 32ms/step - loss: 0.3571 - rmse: 0.5976 - mae: 0.5027 - val_loss: 0.3554 - val_rmse: 0.5961 - val_mae: 0.5013\n",
      "Epoch 12/100\n",
      "3933/3933 [==============================] - 128s 33ms/step - loss: 0.3525 - rmse: 0.5937 - mae: 0.4989 - val_loss: 0.3509 - val_rmse: 0.5923 - val_mae: 0.4976\n",
      "Epoch 13/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3481 - rmse: 0.5900 - mae: 0.4953 - val_loss: 0.3465 - val_rmse: 0.5886 - val_mae: 0.4940\n",
      "Epoch 14/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3438 - rmse: 0.5863 - mae: 0.4918 - val_loss: 0.3423 - val_rmse: 0.5850 - val_mae: 0.4905\n",
      "Epoch 15/100\n",
      "3933/3933 [==============================] - 128s 33ms/step - loss: 0.3397 - rmse: 0.5828 - mae: 0.4884 - val_loss: 0.3382 - val_rmse: 0.5816 - val_mae: 0.4871\n",
      "Epoch 16/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3357 - rmse: 0.5794 - mae: 0.4850 - val_loss: 0.3343 - val_rmse: 0.5782 - val_mae: 0.4838\n",
      "Epoch 17/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3318 - rmse: 0.5760 - mae: 0.4817 - val_loss: 0.3304 - val_rmse: 0.5748 - val_mae: 0.4805\n",
      "Epoch 18/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3281 - rmse: 0.5728 - mae: 0.4785 - val_loss: 0.3267 - val_rmse: 0.5716 - val_mae: 0.4772\n",
      "Epoch 19/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3244 - rmse: 0.5696 - mae: 0.4753 - val_loss: 0.3231 - val_rmse: 0.5684 - val_mae: 0.4741\n",
      "Epoch 20/100\n",
      "3933/3933 [==============================] - 130s 33ms/step - loss: 0.3209 - rmse: 0.5664 - mae: 0.4722 - val_loss: 0.3196 - val_rmse: 0.5653 - val_mae: 0.4710\n",
      "Epoch 21/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3174 - rmse: 0.5634 - mae: 0.4692 - val_loss: 0.3162 - val_rmse: 0.5623 - val_mae: 0.4680\n",
      "Epoch 22/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3141 - rmse: 0.5604 - mae: 0.4663 - val_loss: 0.3129 - val_rmse: 0.5593 - val_mae: 0.4651\n",
      "Epoch 23/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3108 - rmse: 0.5575 - mae: 0.4634 - val_loss: 0.3096 - val_rmse: 0.5565 - val_mae: 0.4622\n",
      "Epoch 24/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3077 - rmse: 0.5547 - mae: 0.4606 - val_loss: 0.3065 - val_rmse: 0.5536 - val_mae: 0.4594\n",
      "Epoch 25/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3046 - rmse: 0.5519 - mae: 0.4578 - val_loss: 0.3035 - val_rmse: 0.5509 - val_mae: 0.4567\n",
      "Epoch 26/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.3016 - rmse: 0.5492 - mae: 0.4552 - val_loss: 0.3005 - val_rmse: 0.5482 - val_mae: 0.4541\n",
      "Epoch 27/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2987 - rmse: 0.5465 - mae: 0.4526 - val_loss: 0.2976 - val_rmse: 0.5455 - val_mae: 0.4515\n",
      "Epoch 28/100\n",
      "3933/3933 [==============================] - 130s 33ms/step - loss: 0.2958 - rmse: 0.5439 - mae: 0.4500 - val_loss: 0.2947 - val_rmse: 0.5429 - val_mae: 0.4490\n",
      "Epoch 29/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2930 - rmse: 0.5413 - mae: 0.4476 - val_loss: 0.2919 - val_rmse: 0.5403 - val_mae: 0.4465\n",
      "Epoch 30/100\n",
      "3933/3933 [==============================] - 130s 33ms/step - loss: 0.2902 - rmse: 0.5387 - mae: 0.4451 - val_loss: 0.2892 - val_rmse: 0.5378 - val_mae: 0.4441\n",
      "Epoch 31/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2876 - rmse: 0.5362 - mae: 0.4428 - val_loss: 0.2865 - val_rmse: 0.5353 - val_mae: 0.4417\n",
      "Epoch 32/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2849 - rmse: 0.5338 - mae: 0.4404 - val_loss: 0.2839 - val_rmse: 0.5328 - val_mae: 0.4394\n",
      "Epoch 33/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2823 - rmse: 0.5313 - mae: 0.4381 - val_loss: 0.2813 - val_rmse: 0.5304 - val_mae: 0.4371\n",
      "Epoch 34/100\n",
      "3933/3933 [==============================] - 130s 33ms/step - loss: 0.2797 - rmse: 0.5289 - mae: 0.4358 - val_loss: 0.2787 - val_rmse: 0.5279 - val_mae: 0.4348\n",
      "Epoch 35/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2771 - rmse: 0.5264 - mae: 0.4335 - val_loss: 0.2762 - val_rmse: 0.5255 - val_mae: 0.4326\n",
      "Epoch 36/100\n",
      "3933/3933 [==============================] - 130s 33ms/step - loss: 0.2746 - rmse: 0.5240 - mae: 0.4313 - val_loss: 0.2736 - val_rmse: 0.5231 - val_mae: 0.4303\n",
      "Epoch 37/100\n",
      "3933/3933 [==============================] - 130s 33ms/step - loss: 0.2721 - rmse: 0.5216 - mae: 0.4291 - val_loss: 0.2711 - val_rmse: 0.5207 - val_mae: 0.4281\n",
      "Epoch 38/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2696 - rmse: 0.5193 - mae: 0.4269 - val_loss: 0.2687 - val_rmse: 0.5184 - val_mae: 0.4259\n",
      "Epoch 39/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2672 - rmse: 0.5169 - mae: 0.4247 - val_loss: 0.2663 - val_rmse: 0.5160 - val_mae: 0.4238\n",
      "Epoch 40/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2648 - rmse: 0.5146 - mae: 0.4226 - val_loss: 0.2639 - val_rmse: 0.5137 - val_mae: 0.4216\n",
      "Epoch 41/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2624 - rmse: 0.5123 - mae: 0.4204 - val_loss: 0.2615 - val_rmse: 0.5114 - val_mae: 0.4195\n",
      "Epoch 42/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2600 - rmse: 0.5099 - mae: 0.4183 - val_loss: 0.2591 - val_rmse: 0.5090 - val_mae: 0.4174\n",
      "Epoch 43/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2577 - rmse: 0.5076 - mae: 0.4162 - val_loss: 0.2568 - val_rmse: 0.5067 - val_mae: 0.4153\n",
      "Epoch 44/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2554 - rmse: 0.5053 - mae: 0.4141 - val_loss: 0.2544 - val_rmse: 0.5044 - val_mae: 0.4132\n",
      "Epoch 45/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2531 - rmse: 0.5030 - mae: 0.4121 - val_loss: 0.2521 - val_rmse: 0.5021 - val_mae: 0.4112\n",
      "Epoch 46/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2508 - rmse: 0.5008 - mae: 0.4100 - val_loss: 0.2499 - val_rmse: 0.4999 - val_mae: 0.4091\n",
      "Epoch 47/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2485 - rmse: 0.4985 - mae: 0.4080 - val_loss: 0.2476 - val_rmse: 0.4976 - val_mae: 0.4071\n",
      "Epoch 48/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2463 - rmse: 0.4962 - mae: 0.4059 - val_loss: 0.2454 - val_rmse: 0.4953 - val_mae: 0.4050\n",
      "Epoch 49/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2440 - rmse: 0.4940 - mae: 0.4039 - val_loss: 0.2431 - val_rmse: 0.4931 - val_mae: 0.4030\n",
      "Epoch 50/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2418 - rmse: 0.4917 - mae: 0.4019 - val_loss: 0.2409 - val_rmse: 0.4908 - val_mae: 0.4010\n",
      "Epoch 51/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2396 - rmse: 0.4895 - mae: 0.3999 - val_loss: 0.2387 - val_rmse: 0.4886 - val_mae: 0.3990\n",
      "Epoch 52/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2374 - rmse: 0.4873 - mae: 0.3979 - val_loss: 0.2365 - val_rmse: 0.4864 - val_mae: 0.3970\n",
      "Epoch 53/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2352 - rmse: 0.4850 - mae: 0.3959 - val_loss: 0.2344 - val_rmse: 0.4841 - val_mae: 0.3950\n",
      "Epoch 54/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2331 - rmse: 0.4828 - mae: 0.3939 - val_loss: 0.2322 - val_rmse: 0.4819 - val_mae: 0.3930\n",
      "Epoch 55/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2310 - rmse: 0.4806 - mae: 0.3919 - val_loss: 0.2301 - val_rmse: 0.4797 - val_mae: 0.3910\n",
      "Epoch 56/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2288 - rmse: 0.4784 - mae: 0.3899 - val_loss: 0.2280 - val_rmse: 0.4775 - val_mae: 0.3891\n",
      "Epoch 57/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2267 - rmse: 0.4762 - mae: 0.3879 - val_loss: 0.2259 - val_rmse: 0.4753 - val_mae: 0.3871\n",
      "Epoch 58/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2246 - rmse: 0.4740 - mae: 0.3860 - val_loss: 0.2238 - val_rmse: 0.4731 - val_mae: 0.3851\n",
      "Epoch 59/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2226 - rmse: 0.4718 - mae: 0.3840 - val_loss: 0.2217 - val_rmse: 0.4709 - val_mae: 0.3832\n",
      "Epoch 60/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2205 - rmse: 0.4696 - mae: 0.3821 - val_loss: 0.2197 - val_rmse: 0.4687 - val_mae: 0.3813\n",
      "Epoch 61/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2185 - rmse: 0.4674 - mae: 0.3802 - val_loss: 0.2177 - val_rmse: 0.4666 - val_mae: 0.3794\n",
      "Epoch 62/100\n",
      "3933/3933 [==============================] - 130s 33ms/step - loss: 0.2165 - rmse: 0.4653 - mae: 0.3783 - val_loss: 0.2157 - val_rmse: 0.4644 - val_mae: 0.3774\n",
      "Epoch 63/100\n",
      "3933/3933 [==============================] - 129s 33ms/step - loss: 0.2145 - rmse: 0.4631 - mae: 0.3763 - val_loss: 0.2136 - val_rmse: 0.4622 - val_mae: 0.3755\n",
      "Epoch 64/100\n",
      "3931/3933 [============================>.] - ETA: 0s - loss: 0.2124 - rmse: 0.4609 - mae: 0.3744"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"  This is the driver code which initializes all the variable, trains the model and save the outputs. \"\"\"\n",
    "    \n",
    "    # Calling the function to switch processing to GPU (if present).\n",
    "    memory_growth_GPU()\n",
    "    \n",
    "    # Initializing variables.\n",
    "    EPOCHS = 100\n",
    "    LEARNING_RATE = 1e-9\n",
    "    BATCH_SIZE = 128\n",
    "    ES_PATIENCE = 3\n",
    "    VAL_SPLIT = 0.2\n",
    "    SEQUENCE = 1\n",
    "    flag = 1\n",
    "    \n",
    "    for input_file in os.listdir(os.path.join(input_dir, final_inputs_dir)):\n",
    "        \"\"\" Loop to iterate through all the input files in the directory for training.\n",
    "        \"\"\"\n",
    "        batch_num = 1\n",
    "        \n",
    "        # Condition to check if the graph directory for the input_file exists. If not, then create one.\n",
    "        if not os.path.isdir(os.path.join(output_dir, graphs_dir, input_file[:-8] + '_S-' + str(SEQUENCE))):\n",
    "            try:\n",
    "                print(\"[INFO]. Graph directory for the input file \\'{}\\' does not exists. Creating the directory.\".format(input_file))\n",
    "                os.makedirs(os.path.join(output_dir, graphs_dir, input_file[:-8] + '_S-' + str(SEQUENCE)))\n",
    "                print(\"[INFO]. Directory created successfully.\")\n",
    "            except:\n",
    "                print(\"[WARNING]. Directory for the input file \\'{}\\' already exists.\".format(input_file))\n",
    "        \n",
    "        for batch in read_feather_in_chunks(os.path.join(input_dir, final_inputs_dir, input_file)):\n",
    "            \"\"\" Loop to iterate through batches in the input feather files. \"\"\"\n",
    "            \n",
    "            # Condition to check if the 'saving model' directory for the input_file exists. If not, then create one.\n",
    "            if not os.path.isdir(os.path.join(output_dir, saved_models_dir, input_file[:-8] + '_S-' + str(SEQUENCE))):\n",
    "                try:\n",
    "                    print(\"[INFO]. Saving model directory for the input file \\'{}\\' does not exists. Creating the directory.\".format(input_file))\n",
    "                    os.makedirs(os.path.join(output_dir, saved_models_dir, input_file[:-8] + '_S-' + str(SEQUENCE), str(batch_num) + '_batch'))\n",
    "                    print(\"[INFO]. Directory created successfully.\")\n",
    "                except:\n",
    "                    print(\"[WARNING]. Directory for the input file \\'{}\\' already exists.\".format(input_file))\n",
    "\n",
    "            # Loop to calculate the tasmax, tasmin and precipitation_flux in the batch.\n",
    "            print(\"[INFO]. Pre-Processing Batch-{} Inputs.\".format(batch_num))\n",
    "            for i in tqdm(range(len(batch))):\n",
    "                batch.iloc[i, 25] += batch.iloc[i, 11]\n",
    "                batch.iloc[i, 26] += batch.iloc[i, 11]    \n",
    "                if batch.iloc[i, 10] != np.inf:\n",
    "                    batch.iloc[i, 27] = (1 + batch.iloc[i, 10] / 100) * batch.iloc[i, 27]\n",
    "            \n",
    "            # Final formatting of the dataframe before traning.\n",
    "            batch = batch.drop(columns=['index', 'time', 'lat', 'lon', 'index_x', 'index_y', 'spatial_ref', 'W', 'T'])\n",
    "            batch.gravel = batch.gravel.astype(int)\n",
    "            batch.clay = batch.clay.astype(int)\n",
    "            batch.silt = batch.silt.astype(int)\n",
    "            batch.sand = batch.sand.astype(int)\n",
    "            batch.awc = batch.awc.astype(int)\n",
    "            batch.cec_soil = batch.cec_soil.astype(int)\n",
    "            batch.texture_class = batch.texture_class.astype(int)\n",
    "            batch.CO2 = batch.CO2.astype(int)\n",
    "            batch['plant-day'] = batch['plant-day'].astype(int)\n",
    "            batch['maturity-day'] = batch['maturity-day'].astype(int)\n",
    "\n",
    "            # Dividing the dataframe in static and dynamic dataframe on the basis of features.\n",
    "            static_data_input = batch[['plant-day', 'maturity-day', 'CO2', 'N', 'A', 'texture_class', 'soil_ph',\n",
    "                                        'soil_caco3', 'cec_soil', 'oc', 'awc', 'sand', 'silt', 'clay', 'gravel']]\n",
    "            static_data_label = batch[['yield_mai']]\n",
    "            weather_array_1 = batch[['tasmax', 'tasmin', 'pr', 'gdd']]\n",
    "            \n",
    "            # Scaling static and dynamic data to assist in the training.\n",
    "            scaler = MinMaxScaler(feature_range=(0.01, 1))\n",
    "            scaled_static_data = scaler.fit_transform(static_data_input)\n",
    "            scaled_static_label = scaler.fit_transform(static_data_label)\n",
    "            scaled_dynamic_data = scaler.fit_transform(weather_array_1)\n",
    "            \n",
    "            # Clear the memory buffer and deleting un-necessary variables.\n",
    "            gc.collect()\n",
    "            del batch, static_data_input, static_data_label, weather_array_1\n",
    "            \n",
    "            # Splitting the static and dynamic dataframe in training and testing set.\n",
    "            test_size = 0.2\n",
    "            fract = 1 - test_size\n",
    "\n",
    "            static_X_train = scaled_static_data[:int(len(scaled_static_data) * fract)]\n",
    "            static_X_test = scaled_static_data[int(len(scaled_static_data) * fract):]\n",
    "\n",
    "            static_Y_train = scaled_static_label[:int(len(scaled_static_label) * fract)]\n",
    "            static_Y_test = scaled_static_label[int(len(scaled_static_label) * fract):]\n",
    "\n",
    "            dynamic_X_train = scaled_dynamic_data[:int(len(scaled_dynamic_data) * fract)]\n",
    "            dynamic_X_test = scaled_dynamic_data[int(len(scaled_dynamic_data) * fract):]\n",
    "\n",
    "            # Clear the memory buffer and deleting un-necessary variables.\n",
    "            gc.collect()\n",
    "            del scaled_static_data, scaled_static_label, scaled_dynamic_data\n",
    "\n",
    "            # Defining the neural network for training the model.\n",
    "            if flag == 1:\n",
    "                dynamic_input = keras.Input(shape = (dynamic_X_train.shape[1], 1), dtype='float32')\n",
    "                inner_lstm1 = LSTM(200, return_sequences=True)(dynamic_input)\n",
    "                inner_lstm2 = LSTM(200, return_sequences=True)(inner_lstm1)\n",
    "                lstm_out = LSTM(200, return_sequences=False)(inner_lstm2)\n",
    "\n",
    "                static_input = keras.Input(shape = (static_X_train.shape[1]))\n",
    "                inner_stat1 = Dense(200, activation='selu')(static_input)\n",
    "                inner_stat1 = Dense(200, activation='selu')(inner_stat1)\n",
    "                inner_stat2 = Dense(200, activation='selu')(inner_stat1)     \n",
    "\n",
    "                x = Concatenate()([lstm_out, inner_stat2])\n",
    "\n",
    "                x = Dense(200, activation='selu')(x)\n",
    "                x = Dense(200, activation='selu')(x)\n",
    "                x = Dense(200, activation='selu')(x)\n",
    "\n",
    "                dynamic_output = Dense(1, activation = 'selu')(x)\n",
    "\n",
    "                model = Model(inputs = [dynamic_input, static_input], outputs = [dynamic_output])\n",
    "\n",
    "                model.compile(loss = keras.metrics.mean_squared_error,\n",
    "                            optimizer = optimizers.Adam(learning_rate = LEARNING_RATE),\n",
    "                            metrics = [keras.metrics.RootMeanSquaredError(name = 'rmse'), 'mae'])\n",
    "\n",
    "                logs = \"./logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 3)\n",
    "                tboard_callback = keras.callbacks.TensorBoard(log_dir = logs, histogram_freq = 1, profile_batch = '500,520')\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    model = keras.models.load_model(os.path.join(output_dir, saved_models_dir, input_file[:-8] + '_S-' + str(SEQUENCE), str(batch_num-1)+'_batch'))\n",
    "                except:\n",
    "                    print(\"[INFO]. Input File has been completed. Moving onto the new input file.\")\n",
    "                    model = keras.models.load_model(prev_model)\n",
    "\n",
    "                es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = ES_PATIENCE)\n",
    "                tboard_callback = keras.callbacks.TensorBoard(log_dir = logs, histogram_freq = 1, profile_batch = '500,520')\n",
    "\n",
    "            # Training the mode on the dataset.\n",
    "            history = model.fit(x = [dynamic_X_train, static_X_train], y = static_Y_train, validation_split = VAL_SPLIT, epochs = EPOCHS, callbacks = [tboard_callback, es], batch_size = BATCH_SIZE)\n",
    "\n",
    "            # Plottting the loss graph and saving it in graph directory.\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('model loss')\n",
    "            plt.ylabel('loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'test'], loc='upper left')\n",
    "            plt.savefig(os.path.join(output_dir, graphs_dir, input_file[:-8] + '_S-' + str(SEQUENCE), \"Batch-{}_loss_stats.jpg\".format(batch_num)))\n",
    "            plt.clf()\n",
    "\n",
    "            # Saving the model after each epoch in corresponding directory..\n",
    "            model.save(os.path.join(output_dir, saved_models_dir, input_file[:-8] + '_S-' + str(SEQUENCE), str(batch_num)+'_batch'))\n",
    "            \n",
    "            # Condition to handle when one input_file is completed and about to switch to another one.\n",
    "            if batch_num == 12:\n",
    "                prev_model = os.path.join(output_dir, saved_models_dir, input_file[:-8] + '_S-' + str(SEQUENCE), str(batch_num) + '_batch')\n",
    "            \n",
    "            # Clearing the memory buffer and incrementing the variables.\n",
    "            gc.collect()\n",
    "            flag += 1\n",
    "            batch_num += 1\n",
    "    \n",
    "        SEQUENCE += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
